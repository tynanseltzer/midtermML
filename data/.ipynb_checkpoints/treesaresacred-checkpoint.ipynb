{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "798\n",
      "[0.20565655 0.15471984 0.09835404 0.0224083  0.17746834 0.20275158\n",
      " 0.09728103 0.04136032]\n",
      "[1 0 1 ... 0 1 1]\n",
      "[0 1 1 ... 0 1 1]\n",
      "Below is our training data analysis\n",
      "638\n",
      "588\n",
      "0.9216300940438872 is our training accuracy\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "Below is our testing data analysis\n",
      "160\n",
      "141\n",
      "0.88125 is our testing accuracy\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from collections import defaultdict\n",
    "\n",
    "from sklearn import metrics \n",
    "\n",
    "import csv\n",
    "import ast\n",
    "import pandas\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "what = pandas.read_csv(\"partiesthush.csv\")\n",
    "\n",
    "df1 = what[['Party_Previous_Vote_ShareLEFT', 'IncumbentLEFT', 'RaisedLEFT',\n",
    "            'SpentLEFT', 'Party_Previous_Vote_ShareRIGHT', 'IncumbentRIGHT', 'RaisedRIGHT', 'SpentRIGHT']]\n",
    "df2 = what[['won']]\n",
    "# print(df2)\n",
    "# print(df1)\n",
    "\n",
    "d1 = df1.fillna(0) \n",
    "d2 = df2.fillna(0)\n",
    "\n",
    "# print(d2)\n",
    "# print(d2)\n",
    "# d2 = np.ravel(d2)\n",
    "\n",
    "# X, y = make_classification(n_samples=1000, n_features=4,\n",
    "#                             n_informative=2, n_redundant=0,\n",
    "#                             random_state=0, shuffle=False)\n",
    "\n",
    "\n",
    "# X, y = d1, d2\n",
    "# print(y)\n",
    "clf = RandomForestClassifier(n_estimators=100, max_depth=2,\n",
    "                              random_state=0)\n",
    "\n",
    "# X = d1.sample(2718)\n",
    "\n",
    "# trainingx = pandas.concat([d1, testingx, testingx]).drop_duplicates(keep=False)\n",
    "\n",
    "# print(trainingx)\n",
    "# # print(testingy)\n",
    "# trainingy = pandas.concat([d2, testingy, testingy]).drop_duplicates(keep=False)\n",
    "\n",
    "# # print(trainingx)\n",
    "# print(trainingy)\n",
    "\n",
    "# print(d2)\n",
    "toterows = np.ravel(d2)\n",
    "print(sum(toterows))\n",
    "\n",
    "combine = d1.join(d2, lsuffix='SpentRIGHT', rsuffix='won')\n",
    "\n",
    "# print(combine)\n",
    "\n",
    "combine = combine.sample(frac = 1)\n",
    "\n",
    "d1 = combine[['Party_Previous_Vote_ShareLEFT', 'IncumbentLEFT', 'RaisedLEFT',\n",
    "            'SpentLEFT', 'Party_Previous_Vote_ShareRIGHT', 'IncumbentRIGHT', 'RaisedRIGHT', 'SpentRIGHT']]\n",
    "d2 = combine[['won']]\n",
    "\n",
    "\n",
    "trainingx = d1.iloc[:1324]\n",
    "\n",
    "testingx = d1.iloc[1324:]\n",
    "\n",
    "# print(testingx)\n",
    "\n",
    "trainingy = d2.iloc[:1324]\n",
    "testingy = d2.iloc[1324:]\n",
    "\n",
    "\n",
    "# print(train)\n",
    "# trainingx = train[['Party_Previous_Vote_ShareLEFT', 'IncumbentLEFT', 'RaisedLEFT',\n",
    "#             'SpentLEFT', 'Party_Previous_Vote_ShareRIGHT', 'IncumbentRIGHT', 'RaisedRIGHT', 'SpentRIGHT']]\n",
    "# trainingy = train[['won']]\n",
    "\n",
    "# print(tester)\n",
    "\n",
    "# testingx = tester[['Party_Previous_Vote_ShareLEFT', 'IncumbentLEFT', 'RaisedLEFT',\n",
    "#             'SpentLEFT', 'Party_Previous_Vote_ShareRIGHT', 'IncumbentRIGHT', 'RaisedRIGHT', 'SpentRIGHT']]\n",
    "# testingy = tester[['won']]\n",
    "\n",
    "\n",
    "# trainingx = d1[d1.index % 4 != 0]\n",
    "# testingx = d1[d1.index % 4 == 0] \n",
    "\n",
    "# trainingy = d2[d2.index % 4 != 0]\n",
    "# testingy = d2[d2.index % 4 == 0] \n",
    "\n",
    "clf.fit(trainingx, np.ravel(trainingy))\n",
    "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
    "            max_depth=2, max_features='auto', max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=None,\n",
    "            oob_score=False, random_state=0, verbose=0, warm_start=False)\n",
    "print(clf.feature_importances_)\n",
    "\n",
    "# print(testingx)\n",
    "traininganswers = clf.predict(trainingx)\n",
    "testinganswers = clf.predict(testingx)\n",
    "# print(testinganswers)\n",
    "\n",
    "print(np.ravel(trainingy))\n",
    "print(traininganswers)\n",
    "\n",
    "realanswers = np.ravel(trainingy)\n",
    "\n",
    "\n",
    "print(\"Below is our training data analysis\")\n",
    "summer = sum(realanswers)\n",
    "print(summer)\n",
    "\n",
    "numcorrect = np.dot(realanswers, traininganswers)\n",
    "\n",
    "print(numcorrect)\n",
    "print(str(numcorrect/summer) + \" is our training accuracy\")\n",
    "\n",
    "print(\"\\n \\n \\n\")\n",
    "\n",
    "print(\"Below is our testing data analysis\")\n",
    "realtestanswers = np.ravel(testingy)\n",
    "\n",
    "summer = sum(realtestanswers)\n",
    "print(summer)\n",
    "numcorrect = np.dot(realtestanswers, testinganswers)\n",
    "\n",
    "print(numcorrect)\n",
    "print(str(numcorrect/summer) + \" is our testing accuracy\")\n",
    "\n",
    "\n",
    "\n",
    "# # testing score\n",
    "# score = metrics.f1_score(trainingy, traininganswers, pos_label=list(set(trainingy)))\n",
    "# training score\n",
    "# score_test = metrics.f1_score(testingy, testinganswers, pos_label=list(set(testingy)))\n",
    "\n",
    "# print(clf.predict([[0, 0, 0, 0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from collections import defaultdict\n",
    "\n",
    "from sklearn import metrics \n",
    "\n",
    "import csv\n",
    "import ast\n",
    "import pandas\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "what = pandas.read_csv(\"2018erthush.csv\")\n",
    "\n",
    "df1 = what[['Party_Previous_Vote_ShareLEFT', 'IncumbentLEFT', 'RaisedLEFT',\n",
    "            'SpentLEFT', 'Party_Previous_Vote_ShareRIGHT', 'IncumbentRIGHT', 'RaisedRIGHT', 'SpentRIGHT']]\n",
    "df2 = what[['won']]\n",
    "# print(df2)\n",
    "# print(df1)\n",
    "\n",
    "d1 = df1.fillna(0) \n",
    "d2 = df2.fillna(0)\n",
    "\n",
    "# print(d2)\n",
    "# print(d2)\n",
    "# d2 = np.ravel(d2)\n",
    "\n",
    "# X, y = make_classification(n_samples=1000, n_features=4,\n",
    "#                             n_informative=2, n_redundant=0,\n",
    "#                             random_state=0, shuffle=False)\n",
    "\n",
    "\n",
    "# X, y = d1, d2\n",
    "# print(y)\n",
    "clf = RandomForestClassifier(n_estimators=100, max_depth=2,\n",
    "                              random_state=0)\n",
    "\n",
    "# X = d1.sample(2718)\n",
    "\n",
    "# trainingx = pandas.concat([d1, testingx, testingx]).drop_duplicates(keep=False)\n",
    "\n",
    "# print(trainingx)\n",
    "# # print(testingy)\n",
    "# trainingy = pandas.concat([d2, testingy, testingy]).drop_duplicates(keep=False)\n",
    "\n",
    "# # print(trainingx)\n",
    "# print(trainingy)\n",
    "\n",
    "# print(d2)\n",
    "toterows = np.ravel(d2)\n",
    "print(sum(toterows))\n",
    "\n",
    "combine = d1.join(d2, lsuffix='SpentRIGHT', rsuffix='won')\n",
    "\n",
    "# print(combine)\n",
    "\n",
    "combine = combine.sample(frac = 1)\n",
    "\n",
    "d1 = combine[['Party_Previous_Vote_ShareLEFT', 'IncumbentLEFT', 'RaisedLEFT',\n",
    "            'SpentLEFT', 'Party_Previous_Vote_ShareRIGHT', 'IncumbentRIGHT', 'RaisedRIGHT', 'SpentRIGHT']]\n",
    "d2 = combine[['won']]\n",
    "\n",
    "\n",
    "trainingx = d1.iloc[:1324]\n",
    "\n",
    "testingx = d1.iloc[1324:]\n",
    "\n",
    "# print(testingx)\n",
    "\n",
    "trainingy = d2.iloc[:1324]\n",
    "testingy = d2.iloc[1324:]\n",
    "\n",
    "\n",
    "# print(train)\n",
    "# trainingx = train[['Party_Previous_Vote_ShareLEFT', 'IncumbentLEFT', 'RaisedLEFT',\n",
    "#             'SpentLEFT', 'Party_Previous_Vote_ShareRIGHT', 'IncumbentRIGHT', 'RaisedRIGHT', 'SpentRIGHT']]\n",
    "# trainingy = train[['won']]\n",
    "\n",
    "# print(tester)\n",
    "\n",
    "# testingx = tester[['Party_Previous_Vote_ShareLEFT', 'IncumbentLEFT', 'RaisedLEFT',\n",
    "#             'SpentLEFT', 'Party_Previous_Vote_ShareRIGHT', 'IncumbentRIGHT', 'RaisedRIGHT', 'SpentRIGHT']]\n",
    "# testingy = tester[['won']]\n",
    "\n",
    "\n",
    "# trainingx = d1[d1.index % 4 != 0]\n",
    "# testingx = d1[d1.index % 4 == 0] \n",
    "\n",
    "# trainingy = d2[d2.index % 4 != 0]\n",
    "# testingy = d2[d2.index % 4 == 0] \n",
    "\n",
    "clf.fit(trainingx, np.ravel(trainingy))\n",
    "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
    "            max_depth=2, max_features='auto', max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=None,\n",
    "            oob_score=False, random_state=0, verbose=0, warm_start=False)\n",
    "print(clf.feature_importances_)\n",
    "\n",
    "# print(testingx)\n",
    "traininganswers = clf.predict(trainingx)\n",
    "testinganswers = clf.predict(testingx)\n",
    "# print(testinganswers)\n",
    "\n",
    "print(np.ravel(trainingy))\n",
    "print(traininganswers)\n",
    "\n",
    "realanswers = np.ravel(trainingy)\n",
    "\n",
    "\n",
    "print(\"Below is our training data analysis\")\n",
    "summer = sum(realanswers)\n",
    "print(summer)\n",
    "\n",
    "numcorrect = np.dot(realanswers, traininganswers)\n",
    "\n",
    "print(numcorrect)\n",
    "print(str(numcorrect/summer) + \" is our training accuracy\")\n",
    "\n",
    "print(\"\\n \\n \\n\")\n",
    "\n",
    "print(\"Below is our testing data analysis\")\n",
    "realtestanswers = np.ravel(testingy)\n",
    "\n",
    "summer = sum(realtestanswers)\n",
    "print(summer)\n",
    "numcorrect = np.dot(realtestanswers, testinganswers)\n",
    "\n",
    "print(numcorrect)\n",
    "print(str(numcorrect/summer) + \" is our testing accuracy\")\n",
    "\n",
    "\n",
    "\n",
    "# # testing score\n",
    "# score = metrics.f1_score(trainingy, traininganswers, pos_label=list(set(trainingy)))\n",
    "# training score\n",
    "# score_test = metrics.f1_score(testingy, testinganswers, pos_label=list(set(testingy)))\n",
    "\n",
    "# print(clf.predict([[0, 0, 0, 0]]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
