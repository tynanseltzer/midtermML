{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.30126392 0.50872877 0.06843058 0.12157672]\n",
      "[1 1 0 ... 0 0 0]\n",
      "[1 1 0 ... 1 1 0]\n",
      "1302\n",
      "1182\n",
      "0.9078341013824884% is our training accuracy\n",
      "438\n",
      "387\n",
      "0.8835616438356164% is our testing accuracy\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from collections import defaultdict\n",
    "\n",
    "from sklearn import metrics \n",
    "\n",
    "import csv\n",
    "import ast\n",
    "import pandas\n",
    "import numpy as np\n",
    "\n",
    "# with open('thushwinnersrf.csv', 'wb') as csvfile:\n",
    "#     spamwriter = csv.writer(csvfile, delimiter='')\n",
    "\n",
    "#     with open('holytrees.csv') as csvfile:\n",
    "#         spamreader = csv.reader(csvfile, delimiter=',', quotechar='|')\n",
    "#         for row in spamreader:\n",
    "#             print(row)\n",
    "#             spamwriter.writerow(row)\n",
    "\n",
    "what = pandas.read_csv(\"thushwinnersrf.csv\")\n",
    "\n",
    "df1 = what[['Party_Previous_Vote_Share', 'Incumbent', 'Raised', 'Spent']]\n",
    "df2 = what[['won']]\n",
    "# print(df2)\n",
    "# print(df1)\n",
    "\n",
    "d1 = df1.fillna(0) \n",
    "d2 = df2.fillna(0)\n",
    "\n",
    "# print(d2)\n",
    "# print(d2)\n",
    "# d2 = np.ravel(d2)\n",
    "\n",
    "# X, y = make_classification(n_samples=1000, n_features=4,\n",
    "#                             n_informative=2, n_redundant=0,\n",
    "#                             random_state=0, shuffle=False)\n",
    "\n",
    "\n",
    "# X, y = d1, d2\n",
    "# print(y)\n",
    "clf = RandomForestClassifier(n_estimators=100, max_depth=2,\n",
    "                              random_state=0)\n",
    "\n",
    "# print(y)\n",
    "# testingx = d1.iloc[::4, :]\n",
    "\n",
    "# testingy = d2.iloc[::4, :]\n",
    "\n",
    "# X = d1.sample(2718)\n",
    "\n",
    "# trainingx = pandas.concat([d1, testingx, testingx]).drop_duplicates(keep=False)\n",
    "\n",
    "# print(trainingx)\n",
    "# # print(testingy)\n",
    "# trainingy = pandas.concat([d2, testingy, testingy]).drop_duplicates(keep=False)\n",
    "\n",
    "# # print(trainingx)\n",
    "# print(trainingy)\n",
    "\n",
    "trainingx = d1[d1.index % 4 != 0]\n",
    "testingx = d1[d1.index % 4 == 0] \n",
    "\n",
    "trainingy = d2[d2.index % 4 != 0]\n",
    "testingy = d2[d2.index % 4 == 0] \n",
    "\n",
    "clf.fit(trainingx, np.ravel(trainingy))\n",
    "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
    "            max_depth=2, max_features='auto', max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=None,\n",
    "            oob_score=False, random_state=0, verbose=0, warm_start=False)\n",
    "print(clf.feature_importances_)\n",
    "\n",
    "# print(testingx)\n",
    "traininganswers = clf.predict(trainingx)\n",
    "testinganswers = clf.predict(testingx)\n",
    "# print(testinganswers)\n",
    "\n",
    "print(np.ravel(trainingy))\n",
    "print(traininganswers)\n",
    "\n",
    "realanswers = np.ravel(trainingy)\n",
    "\n",
    "summer = sum(realanswers)\n",
    "print(summer)\n",
    "\n",
    "numcorrect = np.dot(realanswers, traininganswers)\n",
    "\n",
    "print(numcorrect)\n",
    "print(str(numcorrect/summer) + \"% is our training accuracy\")\n",
    "\n",
    "realtestanswers = np.ravel(testingy)\n",
    "\n",
    "summer = sum(realtestanswers)\n",
    "print(summer)\n",
    "numcorrect = np.dot(realtestanswers, testinganswers)\n",
    "\n",
    "print(numcorrect)\n",
    "print(str(numcorrect/summer) + \"% is our testing accuracy\")\n",
    "\n",
    "\n",
    "# # testing score\n",
    "# score = metrics.f1_score(trainingy, traininganswers, pos_label=list(set(trainingy)))\n",
    "# training score\n",
    "# score_test = metrics.f1_score(testingy, testinganswers, pos_label=list(set(testingy)))\n",
    "\n",
    "# print(clf.predict([[0, 0, 0, 0]]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
